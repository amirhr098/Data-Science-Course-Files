{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('khayyam.txt', 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|برخیز بتا'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolaries = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '|',\n",
       " '؟',\n",
       " 'آ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ٌ',\n",
       " 'َ',\n",
       " 'ّ',\n",
       " 'ٔ',\n",
       " 'پ',\n",
       " 'چ',\n",
       " 'ژ',\n",
       " 'ک',\n",
       " 'گ',\n",
       " 'ی']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabolaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {u:i for i, u in enumerate(vocabolaries)}\n",
    "index2char = np.array(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '|': 3,\n",
       " '؟': 4,\n",
       " 'آ': 5,\n",
       " 'ئ': 6,\n",
       " 'ا': 7,\n",
       " 'ب': 8,\n",
       " 'ت': 9,\n",
       " 'ث': 10,\n",
       " 'ج': 11,\n",
       " 'ح': 12,\n",
       " 'خ': 13,\n",
       " 'د': 14,\n",
       " 'ذ': 15,\n",
       " 'ر': 16,\n",
       " 'ز': 17,\n",
       " 'س': 18,\n",
       " 'ش': 19,\n",
       " 'ص': 20,\n",
       " 'ض': 21,\n",
       " 'ط': 22,\n",
       " 'ظ': 23,\n",
       " 'ع': 24,\n",
       " 'غ': 25,\n",
       " 'ف': 26,\n",
       " 'ق': 27,\n",
       " 'ل': 28,\n",
       " 'م': 29,\n",
       " 'ن': 30,\n",
       " 'ه': 31,\n",
       " 'و': 32,\n",
       " 'ٌ': 33,\n",
       " 'َ': 34,\n",
       " 'ّ': 35,\n",
       " 'ٔ': 36,\n",
       " 'پ': 37,\n",
       " 'چ': 38,\n",
       " 'ژ': 39,\n",
       " 'ک': 40,\n",
       " 'گ': 41,\n",
       " 'ی': 42}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_integer = np.array([char2index[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  8, 16, ..., 14, 42,  0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "ب\n",
      "ر\n",
      "خ\n",
      "ی\n",
      "ز\n",
      " \n",
      "ب\n",
      "ت\n",
      "ا\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(10):\n",
    "    print(index2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (30,), types: tf.int64>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(30, drop_remainder=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> |برخیز بتا بیا ز بهر دل ما\n",
      "|حل\n",
      "--->  کن به جمال خویشتن مشکل ما\n",
      "|یک\n",
      "--->  کوزه شراب تا به هم نوش کنیم\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "for i in sequences.take(3):\n",
    "    print('--->', ''.join(index2char[i.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sit(batch):\n",
    "    input_text = batch[:-1]\n",
    "    target_text = batch[1:]\n",
    "    return input_text, target_text\n",
    "dataset = sequences.map(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((29,), (29,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|برخیز بتا بیا ز بهر دل ما\n",
      "|ح\n",
      "برخیز بتا بیا ز بهر دل ما\n",
      "|حل\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(''.join(index2char[i[0].numpy()]))\n",
    "    print(''.join(index2char[i[1].numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 29), (64, 29)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.batch(64, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolary_size = len(vocabolaries)\n",
    "embedding_dim = 25\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, 25),\n",
    "    tf.keras.layers.GRU(1024, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00324541  0.00037203  0.00050542 ... -0.00116422 -0.00274155\n",
      "  -0.00118266]\n",
      " [ 0.00057866  0.00245944 -0.00120837 ... -0.0041001   0.00017226\n",
      "   0.0002535 ]\n",
      " [ 0.00357819  0.00165197 -0.00034095 ... -0.00157473  0.00075142\n",
      "   0.00054015]\n",
      " ...\n",
      " [ 0.00076378  0.00396095 -0.00125311 ... -0.00216107 -0.00683515\n",
      "   0.00787864]\n",
      " [ 0.00426875  0.00190863 -0.00049967 ... -0.00298239 -0.00644784\n",
      "   0.00304987]\n",
      " [ 0.00447485  0.00141166 -0.00310612 ... -0.00215425 -0.00849032\n",
      "   0.00453205]]\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    output = model.predict(input_text)\n",
    "    print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(29, 1), dtype=int64, numpy=\n",
       "array([[35],\n",
       "       [13],\n",
       "       [25],\n",
       "       [17],\n",
       "       [33],\n",
       "       [19],\n",
       "       [31],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [38],\n",
       "       [11],\n",
       "       [30],\n",
       "       [ 0],\n",
       "       [ 5],\n",
       "       [28],\n",
       "       [25],\n",
       "       [21],\n",
       "       [32],\n",
       "       [40],\n",
       "       [40],\n",
       "       [13],\n",
       "       [41],\n",
       "       [42],\n",
       "       [ 2],\n",
       "       [27],\n",
       "       [18],\n",
       "       [33],\n",
       "       [40],\n",
       "       [ 9]])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si = tf.random.categorical(output[0], num_samples=1)\n",
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 13, 25, 17, 33, 19, 31,  9,  8, 38, 11, 30,  0,  5, 28, 25, 21,\n",
       "       32, 40, 40, 13, 41, 42,  2, 27, 18, 33, 40,  9])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(si, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ّخغزٌشهتبچجن\\nآلغضوککخگی!قسٌکت'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index2char[tf.squeeze(si, axis=-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00324541,  0.00037203,  0.00050542,  0.00300855, -0.00345808,\n",
       "       -0.00229521, -0.00302488,  0.00191844,  0.00100038, -0.00284826,\n",
       "        0.00181447,  0.00453737, -0.00284061, -0.00724095,  0.00240566,\n",
       "        0.0015421 , -0.00342499, -0.00117551, -0.00217069, -0.00056876,\n",
       "        0.00070123, -0.00347687,  0.00488681,  0.0011458 ,  0.00454585,\n",
       "       -0.0037517 , -0.00046795, -0.00093804,  0.00025666, -0.00147039,\n",
       "       -0.00200066, -0.00393228,  0.00171278, -0.00298175,  0.00078911,\n",
       "        0.00062172,  0.00075701,  0.00108924,  0.00141302, -0.00103579,\n",
       "       -0.00116422, -0.00274155, -0.00118266], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 25)          1075      \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, None, 1024)        3228672   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 43)          44075     \n",
      "=================================================================\n",
      "Total params: 3,273,822\n",
      "Trainable params: 3,273,822\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='khayyam/checkpoints', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 6s 570ms/step - loss: 4.0833\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 591ms/step - loss: 3.6942\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 6s 575ms/step - loss: 3.6508\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 6s 587ms/step - loss: 3.3799\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 6s 588ms/step - loss: 3.0961\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 7s 594ms/step - loss: 3.0173\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 2.9842\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 2.9480\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 6s 540ms/step - loss: 2.9029\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 6s 517ms/step - loss: 2.8414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, 25),\n",
    "    tf.keras.layers.GRU(1024, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f27e3335c90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.load_weights(tf.train.latest_checkpoint(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 25)          1075      \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, None, 1024)        3228672   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, None, 43)          44075     \n",
      "=================================================================\n",
      "Total params: 3,273,822\n",
      "Trainable params: 3,273,822\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 23), dtype=int32, numpy=\n",
       "array([[ 8, 31,  1, 30,  7, 29,  1, 13, 14,  7, 32, 30, 14,  1, 11,  7,\n",
       "        30,  1, 32,  1, 13, 16, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "input_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generated = []\n",
    "for i in range(10):\n",
    "    predictions = model_2.predict(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predicted_ids = tf.random.categorical(predictions, num_samples=1).numpy()\n",
    "    input_eval = tf.expand_dims(tf.squeeze(predicted_ids, axis=-1).numpy(), 0).numpy()\n",
    "    text_generated.append(index2char[tf.squeeze(predicted_ids, axis=-1).numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عکنتخبک ر| دهتنن  رن نن\n",
      "لشن هگره گ\n",
      "مٔممباشد ت||\n",
      "جدی\n",
      " سا مااش\n",
      "    ببننبف\n",
      "ف\n",
      " امراخین\n",
      " وبکلدوه\n",
      "دان\n",
      "سمچ  یی|توو\n",
      "دخ وا ویزم \n",
      " ید!حتز|سرازسالاخرن| زغ\n",
      "آ\n",
      " ت   |تنی اا نسگمختهم\n",
      "بواوگرنو ر|اهمحر  نرا |\n",
      "شد ن س\n",
      "دبووب   ش افنچود\n",
      "ظآشلع\n",
      "  و ه ت|خبدف  ش| \n"
     ]
    }
   ],
   "source": [
    "for i in text_generated:\n",
    "    print(''.join(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
