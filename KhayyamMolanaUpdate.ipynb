{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('khayyam.txt', 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|برخیز بتا'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolaries = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '|',\n",
       " '؟',\n",
       " 'ء',\n",
       " 'آ',\n",
       " 'ؤ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ة',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ً',\n",
       " 'ٌ',\n",
       " 'َ',\n",
       " 'ّ',\n",
       " 'ٔ',\n",
       " 'پ',\n",
       " 'چ',\n",
       " 'ژ',\n",
       " 'ک',\n",
       " 'گ',\n",
       " 'ی']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabolaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {u:i for i, u in enumerate(vocabolaries)}\n",
    "index2char = np.array(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '|': 3,\n",
       " '؟': 4,\n",
       " 'ء': 5,\n",
       " 'آ': 6,\n",
       " 'ؤ': 7,\n",
       " 'ئ': 8,\n",
       " 'ا': 9,\n",
       " 'ب': 10,\n",
       " 'ة': 11,\n",
       " 'ت': 12,\n",
       " 'ث': 13,\n",
       " 'ج': 14,\n",
       " 'ح': 15,\n",
       " 'خ': 16,\n",
       " 'د': 17,\n",
       " 'ذ': 18,\n",
       " 'ر': 19,\n",
       " 'ز': 20,\n",
       " 'س': 21,\n",
       " 'ش': 22,\n",
       " 'ص': 23,\n",
       " 'ض': 24,\n",
       " 'ط': 25,\n",
       " 'ظ': 26,\n",
       " 'ع': 27,\n",
       " 'غ': 28,\n",
       " 'ف': 29,\n",
       " 'ق': 30,\n",
       " 'ل': 31,\n",
       " 'م': 32,\n",
       " 'ن': 33,\n",
       " 'ه': 34,\n",
       " 'و': 35,\n",
       " 'ً': 36,\n",
       " 'ٌ': 37,\n",
       " 'َ': 38,\n",
       " 'ّ': 39,\n",
       " 'ٔ': 40,\n",
       " 'پ': 41,\n",
       " 'چ': 42,\n",
       " 'ژ': 43,\n",
       " 'ک': 44,\n",
       " 'گ': 45,\n",
       " 'ی': 46}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_integer = np.array([char2index[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 10, 19, ..., 31,  9, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "ب\n",
      "ر\n",
      "خ\n",
      "ی\n",
      "ز\n",
      " \n",
      "ب\n",
      "ت\n",
      "ا\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(10):\n",
    "    print(index2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (101,), types: tf.int64>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(101, drop_remainder=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> |برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش که \n",
      "---> کوزه ها کنند از گل ما\n",
      "|چون عهده نمی شود کسی فردا را\n",
      "|حالی خوش دار این دل پر سودا را\n",
      "|می نوش به ماهتاب\n",
      "--->  ای ماه که ماه\n",
      "|بسیار بتابد و نیابد ما را\n",
      "|قرآن که مهین کلام خوانند آن را\n",
      "|گه گاه نه بر دوام خوانند آ\n"
     ]
    }
   ],
   "source": [
    "for i in sequences.take(3):\n",
    "    print('--->', ''.join(index2char[i.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sit(batch):\n",
    "    input_text = batch[:-1]\n",
    "    target_text = batch[1:]\n",
    "    return input_text, target_text\n",
    "dataset = sequences.map(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش که\n",
      "برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش که \n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(''.join(index2char[i[0].numpy()]))\n",
    "    print(''.join(index2char[i[1].numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.batch(64, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolary_size = len(vocabolaries)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00091032 -0.01065248 -0.00276685 ... -0.00311616 -0.01000043\n",
      "   0.00622381]\n",
      " [ 0.01249189 -0.01199279 -0.00528852 ...  0.00613781 -0.00536665\n",
      "  -0.00217031]\n",
      " [ 0.00802283 -0.00017949  0.00494839 ...  0.00456399 -0.01974823\n",
      "   0.00710435]\n",
      " ...\n",
      " [ 0.01679767 -0.00580759 -0.00136256 ... -0.01375992 -0.00782239\n",
      "  -0.0134883 ]\n",
      " [ 0.00117025 -0.0101225  -0.00244823 ... -0.00958827 -0.00711462\n",
      "  -0.01956189]\n",
      " [ 0.0088116  -0.01171549  0.00034929 ... -0.00574466  0.01293677\n",
      "   0.00230383]]\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    output = model.predict(input_text)\n",
    "    print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1), dtype=int64, numpy=\n",
       "array([[ 4],\n",
       "       [26],\n",
       "       [25],\n",
       "       [37],\n",
       "       [17],\n",
       "       [45],\n",
       "       [19],\n",
       "       [27],\n",
       "       [42],\n",
       "       [37],\n",
       "       [36],\n",
       "       [21],\n",
       "       [18],\n",
       "       [37],\n",
       "       [ 6],\n",
       "       [22],\n",
       "       [11],\n",
       "       [ 7],\n",
       "       [38],\n",
       "       [41],\n",
       "       [35],\n",
       "       [37],\n",
       "       [23],\n",
       "       [ 5],\n",
       "       [ 2],\n",
       "       [20],\n",
       "       [ 8],\n",
       "       [33],\n",
       "       [26],\n",
       "       [ 4],\n",
       "       [24],\n",
       "       [36],\n",
       "       [37],\n",
       "       [ 0],\n",
       "       [32],\n",
       "       [11],\n",
       "       [11],\n",
       "       [34],\n",
       "       [21],\n",
       "       [22],\n",
       "       [ 6],\n",
       "       [14],\n",
       "       [23],\n",
       "       [37],\n",
       "       [36],\n",
       "       [45],\n",
       "       [19],\n",
       "       [ 7],\n",
       "       [14],\n",
       "       [17],\n",
       "       [44],\n",
       "       [31],\n",
       "       [11],\n",
       "       [26],\n",
       "       [ 9],\n",
       "       [31],\n",
       "       [12],\n",
       "       [13],\n",
       "       [14],\n",
       "       [41],\n",
       "       [29],\n",
       "       [18],\n",
       "       [ 0],\n",
       "       [ 6],\n",
       "       [17],\n",
       "       [23],\n",
       "       [26],\n",
       "       [37],\n",
       "       [39],\n",
       "       [12],\n",
       "       [20],\n",
       "       [ 6],\n",
       "       [42],\n",
       "       [10],\n",
       "       [19],\n",
       "       [ 0],\n",
       "       [38],\n",
       "       [45],\n",
       "       [ 8],\n",
       "       [ 5],\n",
       "       [18],\n",
       "       [36],\n",
       "       [38],\n",
       "       [25],\n",
       "       [12],\n",
       "       [32],\n",
       "       [ 1],\n",
       "       [22],\n",
       "       [16],\n",
       "       [46],\n",
       "       [29],\n",
       "       [22],\n",
       "       [26],\n",
       "       [37],\n",
       "       [23],\n",
       "       [23],\n",
       "       [16],\n",
       "       [ 0],\n",
       "       [24],\n",
       "       [24]])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si = tf.random.categorical(output[0], num_samples=1)\n",
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 26, 25, 37, 17, 45, 19, 27, 42, 37, 36, 21, 18, 37,  6, 22, 11,\n",
       "        7, 38, 41, 35, 37, 23,  5,  2, 20,  8, 33, 26,  4, 24, 36, 37,  0,\n",
       "       32, 11, 11, 34, 21, 22,  6, 14, 23, 37, 36, 45, 19,  7, 14, 17, 44,\n",
       "       31, 11, 26,  9, 31, 12, 13, 14, 41, 29, 18,  0,  6, 17, 23, 26, 37,\n",
       "       39, 12, 20,  6, 42, 10, 19,  0, 38, 45,  8,  5, 18, 36, 38, 25, 12,\n",
       "       32,  1, 22, 16, 46, 29, 22, 26, 37, 23, 23, 16,  0, 24, 24])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(si, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'؟ظطٌدگرعچًٌسذٌآشةؤَپوٌصء!زئنظ؟ضًٌ\\nمةةهسشآجصًٌگرؤجدکلةظالتثجپفذ\\nآدصظٌّتزآچبر\\nَگئءذًَطتم شخیفشظٌصصخ\\nضض'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index2char[tf.squeeze(si, axis=-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.1031846e-04, -1.0652477e-02, -2.7668499e-03,  8.0151083e-03,\n",
       "        6.7482088e-03,  1.3226552e-02,  8.8221245e-03,  1.1680550e-03,\n",
       "        1.6145175e-05,  1.1015472e-02, -7.8903488e-04, -2.7878855e-03,\n",
       "        4.0753628e-05, -1.3159969e-03,  7.9447832e-03,  2.3272196e-03,\n",
       "       -4.6412339e-03,  3.2124023e-03, -1.7258890e-02,  1.4421007e-02,\n",
       "       -6.5471772e-03,  3.4239872e-03,  1.3249269e-02,  7.7808877e-03,\n",
       "       -3.5939631e-03,  8.9376196e-03, -5.5991383e-03, -3.9480301e-04,\n",
       "        6.0380795e-03, -4.8489720e-03, -8.3467979e-03,  1.1604073e-02,\n",
       "       -1.0743539e-02,  1.0800222e-03, -7.3164375e-03,  5.6805396e-03,\n",
       "        3.8239043e-03, -1.4297187e-03, -1.7495240e-03,  1.6684338e-02,\n",
       "       -1.0629360e-02, -2.9962743e-04, -5.4808506e-03, -5.1780995e-03,\n",
       "       -3.1161553e-03, -1.0000431e-02,  6.2238057e-03], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 256)         12032     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, None, 1024)        3938304   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 47)          48175     \n",
      "=================================================================\n",
      "Total params: 3,998,511\n",
      "Trainable params: 3,998,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='khayyammolana/checkpoints', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 6s 570ms/step - loss: 4.0833\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 591ms/step - loss: 3.6942\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 6s 575ms/step - loss: 3.6508\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 6s 587ms/step - loss: 3.3799\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 6s 588ms/step - loss: 3.0961\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 7s 594ms/step - loss: 3.0173\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 2.9842\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 2.9480\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 6s 540ms/step - loss: 2.9029\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 6s 517ms/step - loss: 2.8414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=100, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'khayyammolana/checkpoints'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('khayyammolana/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe35ecbfb10>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.load_weights(tf.train.latest_checkpoint('khayyammolana'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 256)         12032     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, None, 1024)        3938304   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 47)          48175     \n",
      "=================================================================\n",
      "Total params: 3,998,511\n",
      "Trainable params: 3,998,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 23), dtype=int32, numpy=\n",
       "array([[10, 34,  1, 33,  9, 32,  1, 16, 17,  9, 35, 33, 17,  1, 14,  9,\n",
       "        33,  1, 35,  1, 16, 19, 17]], dtype=int32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "input_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "10\n",
      "46\n",
      "9\n",
      "33\n",
      "1\n",
      "32\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "9\n",
      "10\n",
      "17\n",
      "46\n",
      "31\n",
      "1\n",
      "35\n",
      "1\n",
      "45\n",
      "32\n",
      "0\n",
      "3\n",
      "33\n",
      "9\n",
      "30\n",
      "34\n",
      "40\n",
      "1\n",
      "14\n",
      "21\n",
      "32\n",
      "1\n",
      "35\n",
      "31\n",
      "46\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "10\n",
      "21\n",
      "1\n",
      "10\n",
      "17\n",
      "46\n",
      "17\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "10\n",
      "32\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "10\n",
      "19\n",
      "1\n",
      "6\n",
      "28\n",
      "9\n",
      "20\n",
      "1\n",
      "44\n",
      "19\n",
      "17\n",
      "0\n",
      "3\n",
      "45\n",
      "9\n",
      "34\n",
      "1\n",
      "10\n",
      "28\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "17\n",
      "22\n",
      "32\n",
      "33\n",
      "9\n",
      "33\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "22\n",
      "33\n",
      "9\n",
      "21\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "10\n",
      "17\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "42\n",
      "19\n",
      "16\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "32\n",
      "33\n",
      "1\n",
      "17\n",
      "19\n",
      "1\n",
      "17\n",
      "31\n",
      "46\n",
      "0\n",
      "3\n",
      "45\n",
      "19\n",
      "1\n",
      "33\n",
      "32\n",
      "9\n",
      "20\n",
      "1\n",
      "35\n",
      "1\n",
      "19\n",
      "35\n",
      "20\n",
      "1\n",
      "32\n",
      "46\n",
      "1\n",
      "6\n",
      "19\n",
      "17\n",
      "1\n",
      "21\n",
      "16\n",
      "33\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "33\n",
      "46\n",
      "44\n",
      "1\n",
      "35\n",
      "1\n",
      "10\n",
      "17\n",
      "22\n",
      "1\n",
      "20\n",
      "46\n",
      "33\n",
      "1\n",
      "33\n",
      "9\n",
      "33\n",
      "1\n",
      "42\n",
      "19\n",
      "9\n",
      "0\n",
      "3\n",
      "34\n",
      "19\n",
      "1\n",
      "42\n",
      "34\n",
      "1\n",
      "10\n",
      "19\n",
      "1\n",
      "12\n",
      "21\n",
      "35\n",
      "46\n",
      "19\n",
      "1\n",
      "42\n",
      "46\n",
      "33\n",
      "34\n",
      "1\n",
      "31\n",
      "14\n",
      "12\n",
      "1\n",
      "35\n",
      "1\n",
      "21\n",
      "16\n",
      "9\n",
      "33\n",
      "1\n",
      "35\n",
      "1\n",
      "19\n",
      "35\n",
      "15\n",
      "1\n",
      "34\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "6\n",
      "33\n",
      "1\n",
      "9\n",
      "13\n",
      "19\n",
      "1\n",
      "32\n",
      "46\n",
      "1\n",
      "10\n",
      "9\n",
      "20\n",
      "46\n",
      "1\n",
      "17\n",
      "16\n",
      "35\n",
      "46\n",
      "22\n",
      "1\n",
      "35\n",
      "1\n",
      "17\n",
      "22\n",
      "9\n",
      "17\n",
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "32\n",
      "46\n",
      "9\n",
      "33\n",
      "1\n",
      "16\n",
      "35\n",
      "9\n",
      "10\n",
      "1\n",
      "14\n",
      "21\n",
      "12\n",
      "1\n",
      "35\n",
      "1\n",
      "45\n",
      "9\n",
      "34\n",
      "1\n",
      "6\n",
      "33\n",
      "1\n",
      "16\n",
      "31\n",
      "46\n",
      "1\n",
      "14\n",
      "35\n",
      "1\n",
      "10\n",
      "19\n",
      "17\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "0\n",
      "3\n",
      "41\n",
      "46\n",
      "22\n",
      "1\n",
      "6\n",
      "19\n",
      "17\n",
      "1\n",
      "30\n",
      "19\n",
      "23\n",
      "1\n",
      "17\n",
      "46\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "35\n",
      "9\n",
      "1\n",
      "19\n",
      "34\n",
      "9\n",
      "33\n",
      "0\n",
      "3\n",
      "42\n",
      "22\n",
      "32\n",
      "34\n",
      "40\n",
      "1\n",
      "16\n",
      "35\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "10\n",
      "29\n",
      "33\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "19\n",
      "46\n",
      "45\n",
      "1\n",
      "9\n",
      "35\n",
      "0\n",
      "3\n",
      "10\n",
      "21\n",
      "1\n",
      "45\n",
      "19\n",
      "9\n",
      "20\n",
      "1\n",
      "6\n",
      "10\n",
      "21\n",
      "12\n",
      "1\n",
      "33\n",
      "30\n",
      "22\n",
      "9\n",
      "33\n",
      "1\n",
      "35\n",
      "1\n",
      "13\n",
      "10\n",
      "9\n",
      "10\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "44\n",
      "1\n",
      "6\n",
      "35\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "31\n",
      "30\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "10\n",
      "46\n",
      "16\n",
      "1\n",
      "35\n",
      "1\n",
      "33\n",
      "35\n",
      "0\n",
      "3\n",
      "10\n",
      "9\n",
      "1\n",
      "22\n",
      "32\n",
      "9\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "31\n",
      "30\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "1\n",
      "21\n",
      "35\n",
      "20\n",
      "46\n",
      "1\n",
      "35\n",
      "1\n",
      "17\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "10\n",
      "46\n",
      "9\n",
      "10\n",
      "9\n",
      "33\n",
      "34\n",
      "9\n",
      "46\n",
      "1\n",
      "10\n",
      "46\n",
      "1\n",
      "42\n",
      "33\n",
      "17\n",
      "46\n",
      "1\n",
      "22\n",
      "44\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "9\n",
      "33\n",
      "17\n",
      "19\n",
      "1\n",
      "6\n",
      "1\n",
      "32\n",
      "9\n",
      "17\n",
      "19\n",
      "1\n",
      "32\n",
      "17\n",
      "34\n",
      "1\n",
      "17\n",
      "9\n",
      "17\n",
      "9\n",
      "33\n",
      "1\n",
      "46\n",
      "44\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "text_generated = ['به نام خداوند جان و خرد']\n",
    "for i in range(500):\n",
    "    predictions = model_2.predict(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "#     predicted_ids = tf.random.categorical(predictions, num_samples=1).numpy()\n",
    "    predicted_ids = np.array(predictions.numpy()).argmax(axis=1).reshape(-1, 1)[-1][0]\n",
    "    print(predicted_ids)\n",
    "    message = np.append(input_eval[0].numpy(), predicted_ids)[1:]\n",
    "    input_eval = tf.expand_dims(message, 0)\n",
    "    text_generated.append(index2char[predicted_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['به نام خداوند جان و خرد',\n",
       " '|در بیان ماند از ابدیل و گم',\n",
       " '|ناقهٔ جسم ولی را بس بدید',\n",
       " '|چون بماند از خبر آغاز کرد',\n",
       " '|گاه بغد از دشمنان این را شناس',\n",
       " '|چون بداند چرخ را من در دلی',\n",
       " '|گر نماز و روز می آرد سخن',\n",
       " '|چون نیک و بدش زین نان چرا',\n",
       " '|هر چه بر تسویر چینه لجت و سخان و روح هست',\n",
       " '|آن اثر می بازی دخویش و دشاد',\n",
       " '|در میان خواب جست و گاه آن خلی جو برد این',\n",
       " '|پیش آرد قرص دین را وا رهان',\n",
       " '|چشمهٔ خون را بفن از ریگ او',\n",
       " '|بس گراز آبست نقشان و ثباب',\n",
       " '|چونک آواز خلق از بیخ و نو',\n",
       " '|با شما از خلق این سوزی و دست',\n",
       " '|در بیابانهای بی چندی شکست',\n",
       " '|اندر آ مادر مده دادان یکی']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(text_generated).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "|در بیان ماند از ابدیل و گم\n",
      "|ناقهٔ جسم ولی را بس بدید\n",
      "|چون بماند از خبر آغاز کرد\n",
      "|گاه بغد از دشمنان این را شناس\n",
      "|چون بداند چرخ را من در دلی\n",
      "|گر نماز و روز می آرد سخن\n",
      "|چون نیک و بدش زین نان چرا\n",
      "|هر چه بر تسویر چینه لجت و سخان و روح هست\n",
      "|آن اثر می بازی دخویش و دشاد\n",
      "|در میان خواب جست و گاه آن خلی جو برد این\n",
      "|پیش آرد قرص دین را وا رهان\n",
      "|چشمهٔ خون را بفن از ریگ او\n",
      "|بس گراز آبست نقشان و ثباب\n",
      "|چونک آواز خلق از بیخ و نو\n",
      "|با شما از خلق این سوزی و دست\n",
      "|در بیابانهای بی چندی شکست\n",
      "|اندر آ مادر مده دادان یکی\n"
     ]
    }
   ],
   "source": [
    "for i in ''.join(text_generated).split('\\n'):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
